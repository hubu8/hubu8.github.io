# 基于yolo算法的目标识别与检测


<!--more-->

## 算法概述

YOLO（You Only Look Once）系列的首个版本由 Joseph Redmon 等人于 2015 年开创性提出。其核心设计目标在于将复杂的目标检测流程简化为单次回归问题，依托一个端到端的卷积神经网络（CNN）架构，直接对输入图像中的目标边界框与类别进行精准预测。简而言之，YOLO 致力于教会计算机系统如何高效识别图像中的各类物体，诸如常见的猫、狗、苹果、汽车等，并且能够精确确定这些物体在图像中的具体位置，摆脱传统方法的盲目性与不确定性。

## YOLO 算法核心流程

### （一）预测阶段上：类别与框的初始生成

当一幅全新的图像输入至已训练完备的 YOLO 模型时，模型首先将图像均匀划分为 7×7 共计 49 个小方格，在专业术语体系中被称为 grid cell。每个 grid cell 肩负两项关键任务：其一，负责生成两个以该 grid cell 为中心的预测边界框（bounding box，简称 bbox），这两个 bbox 通过 x、y、w、h、c 五个参数予以精准界定，其中（x，y）代表预测框中心点的坐标，（w，h）表示框的宽度与高度，而 c 则用于表征该框的可信度（confidence）；其二，对该 grid cell 所处区域内可能存在的物体类别进行预测，物体类别的具体数量与训练所采用的数据集密切相关，在 YOLO 算法的原始论文中，其数据集涵盖 20 种不同物体类别。基于上述流程，在此阶段，模型共计会生成 7×7×2 个 bbox，相应的参数数量高达 7×7×2×5×20 个。后续通过一系列精细的后处理操作，旨在筛选并保留针对不同物体识别效果最佳的边界框。

![image-20250612212539410](images/image-20250612212539410.png)

### （二）预测阶段下：边界框的筛选与保留

在前述步骤生成众多边界框之后，如何从中筛选出最为精准、可靠的边界框成为关键环节。聚焦于某一特定的 grid cell，以落在图像中汽车位置的 grid cell 为例，由于其与汽车位置高度重合，所生成的较大边界框因能更精准框选汽车，其置信度显著高于小框，这一置信度差异在可视化呈现中可通过线条粗细程度予以直观反映。同理，对于未包含任何物体的 grid cell，无论其将该区域判定为何种物体类别，其置信度均处于较低水平，对应边界框线条较细。

![image-20250612212604356](images/image-20250612212604356.png)

进一步地，针对图像中所有 grid cell 生成的共计 98 个 bbox，采取置信度分数低分数过滤策略，将置信度过低的 bbox 直接置零，此举旨在大幅提升运算效率。随后，运用[非极大值抑制](https://zhida.zhihu.com/search?content_id=252213848&content_type=Article&match_order=1&q=非极大值抑制&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDk5MDcxODYsInEiOiLpnZ7mnoHlpKflgLzmipHliLYiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyNTIyMTM4NDgsImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.ZOd0l7SnNH8ZP-MtnLztYh6lY_43kv0VU8EBKw7SGVE&zhida_source=entity)（NMS）算法对剩余 bbox 进行深度筛选。

![image-20250612212951060](images/image-20250612212951060.png)

NMS 算法的核心思想在于保留相近区域内得分最高的 bbox，而非单纯追求全图得分最高，这是考虑到图像中可能存在多个同类物体的实际情况。具体而言，在 NMS 算法执行过程中，首先对 bbox 依据置信度进行降序排序，以 1、2、3、4 分别标记置信度从高到低的四个 bbox 为例：第一轮比较时，将 1 与其他所有 bbox 逐一对比，若 1 与 2 的交并比（IOU）过大，表明二者极有可能是对同一物体的重复框选，此时保留得分最高的 1，将 2 置零；若 1 与 3 的 IOU 较小，则保留两者；依此类推完成第一轮比较。第二轮从剩余未被置零的 bbox 中选取起始点，如从 3 开始，重复上述比较过程，直至所有 bbox 均完成比较。最终，经过 NMS 算法处理后，仅保留少数得分最高且互不重叠过多的边界框，实现精准的目标定位。

![img](images/v2-cdbed2ecdb785556f1b41b2fd0095ca7_1440w.jpg)

### （三）训练阶段：模型的学习与优化

1. **数据输入与标注**：

训练 YOLO 模型的首要步骤是构建规模庞大且标注精准的数据集，将成千上万张已精心标注物体类别及位置信息的图像输入至模型 f。对于每一张输入图像 X，其附带详细的物体标注信息，例如图像中存在汽车、苹果等物体的具体位置与类别标签，以此完成模型的初步知识传授。

2. **损失函数构建**：

在模型接收输入图像并输出其预测结果 f (X) 后，需要与预先标注的真实结果 y 进行比对。为促使模型的预测结果无限趋近于真实标签，即达成 f (X) → y 的优化目标，构建科学合理的损失函数至关重要。

![img](images/v2-812b46e890034277c7056efd2b548aed_1440w.jpg)

在 YOLO 算法的原始设计中，损失函数 loss 综合考量多个关键因素，具体包括：生成的 bbox 中心点定位误差，反映预测框中心位置与真实框中心的偏差程度；生成的 bbox 宽高定位误差，衡量框的大小预测准确性；该 grid cell 包含有物体时的置信度误差，确保对存在物体区域的置信度预测精准；该 grid cell 不含有物体时的置信度误差，避免对空区域的误判；以及该 grid cell 的分类误差，保障物体类别预测的正确性。通过对这些误差项的加权求和，构建出完整的损失函数，以量化模型预测结果与真实标签之间的差异。

3. **模型迭代优化**：

重复进行上述训练过程，历经多轮迭代训练，持续监测损失函数值的变化趋势。随着训练轮次的递增，损失函数值逐步趋于稳定，表明模型在不断学习与优化过程中，逐渐掌握目标识别与检测的核心规律，提升预测准确性与稳定性。

![img](images/v2-05937209ac1c56f1bf6b120de2ae0af2_1440w.jpg)

https://www.ultralytics.com/

